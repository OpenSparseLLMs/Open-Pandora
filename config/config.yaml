model:
  pretrained_checkpoint: null
  dynamicrafter_config: ./DynamiCrafter/configs/inference_512_v1.0.yaml
  base_learning_rate: 1.0e-06
  scale_lr: false
  do_alignment: false
  monitor: val/rec_loss

data:
  data_dir: ./Datasets
  meta_path: webvid_2m.csv
  video_length: 16
  frame_stride: 6
  load_raw_resolution: true
  resolution: [320, 512]
  spatial_transform: resize_center_crop
  random_fs: true  ## if true, we uniformly sample fs with max_fs=frame_stride (above)
  batch_size: 1
  num_workers: 12

lightning:
  precision: 16
  strategy: deepspeed_stage_2
  trainer:
    benchmark: True
    accumulate_grad_batches: 2
    max_steps: 1000000
    # logger
    log_every_n_steps: 50
    # val
    val_check_interval: 0.5
    gradient_clip_algorithm: 'norm'
    gradient_clip_val: 0.5
    num_nodes: 1
  callbacks:
    model_checkpoint:
      target: pytorch_lightning.callbacks.ModelCheckpoint
      params:
        every_n_train_steps: 10000 
        filename: "{epoch}-{step}"
        save_weights_only: True
        save_top_k: 1